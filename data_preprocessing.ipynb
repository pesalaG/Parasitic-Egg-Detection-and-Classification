{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Dataset COCO JSON Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "img_dir = '/content/chula-parasite-dataset/Chula-ParasiteEgg-11_test/test/data'\n",
    "classes = ('Ascaris lumbricoides', 'Capillaria philippinensis', 'Enterobius vermicularis', 'Fasciolopsis buski',\n",
    "           'Hookworm egg', 'Hymenolepis diminuta', 'Hymenolepis nana', 'Opisthorchis viverrine',\n",
    "           'Paragonimus spp', 'Taenia spp. egg', 'Trichuris trichiura')\n",
    "dataset_name = 'ParEgg'\n",
    "\n",
    "#list all images in directory\n",
    "img_paths = [ [f.path, f.name] for f in os.scandir(img_dir) if f.name.split('.')[-1] in ('jpg', 'png', 'jpeg', 'bmp')]\n",
    "images = []\n",
    "id = 1\n",
    "for img_path, img_name in img_paths:\n",
    "    img = Image.open(img_path)\n",
    "    width, height = img.size\n",
    "    images.append({'id': id,\n",
    "                   'file_name': img_name,\n",
    "                   'height': height,\n",
    "                   'width': width,\n",
    "                   'license': None,\n",
    "                   'coco_url': None})\n",
    "    id+=1\n",
    "#add some general info\n",
    "info = {'date': datetime.today().strftime('%Y-%m-%d'),\n",
    "        'author': 'tureckova',\n",
    "        'describtion': dataset_name}\n",
    "categories = []\n",
    "for ind, cls in enumerate(classes):\n",
    "    categories.append({'id': ind,\n",
    "                       'name': cls})\n",
    "coco_json = {'info': info,\n",
    "             'licenses':[],\n",
    "             'categories': categories,\n",
    "             'images': images,\n",
    "             'annotations': []}\n",
    "#save output json file\n",
    "with open('/content/chula-parasite-dataset/Chula-ParasiteEgg-11_test/test/'+'test.json','w') as file:\n",
    "    json.dump(coco_json, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCO Annotation Splitter for K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import os\n",
    "\n",
    "def get_annotation_split(annotations, image_index):\n",
    "    \"\"\"annotations: coco dictionary with annotations\n",
    "       image_index: index of images desired in output split\"\"\"\n",
    "    img_list = []\n",
    "    ann_list = []\n",
    "    real_image_indexes = []\n",
    "    for ind in image_index:\n",
    "        real_image_indexes.append(annotations['images'][ind]['id'])\n",
    "        img_list.append(annotations['images'][ind])\n",
    "    for ann in annotations['annotations']:\n",
    "        if ann['image_id'] in real_image_indexes:\n",
    "            ann_list.append(ann)\n",
    "    annotations_split = {'info': annotations['info'],\n",
    "                         'licenses': annotations['licenses'],\n",
    "                         'images': img_list,\n",
    "                         'annotations': ann_list,\n",
    "                         'categories': annotations['categories']\n",
    "                         }\n",
    "    return annotations_split\n",
    "\n",
    "# file with all annotation\n",
    "annotations_file = '/content/chula-parasite-dataset/Chula-ParasiteEgg-11/Chula-ParasiteEgg-11/Chula-ParasiteEgg-11/labels.json'\n",
    "annotations_file_cut = 'Chula-ParasiteEgg-11/cut_960x1280__coco.json'\n",
    "output_folder = '/content/output_directory/'\n",
    "n_splits = 5\n",
    "\n",
    "# load annotations\n",
    "with open(annotations_file,'r') as file:\n",
    "    annotations = json.load(file)\n",
    "\n",
    "base_dir = output_folder+str(n_splits)+'-fold/'\n",
    "if not os.path.exists(base_dir): os.mkdir(base_dir)\n",
    "images_index = [i for i in range(len(annotations['images']))]\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "kf.get_n_splits(images_index)\n",
    "counter = 0\n",
    "for train_index, val_index in kf.split(images_index):\n",
    "    train_annotations = get_annotation_split(annotations, train_index)\n",
    "    val_annotations = get_annotation_split(annotations, val_index)\n",
    "    split_dir = base_dir + 'fold-' + str(counter) + '/'\n",
    "    if not os.path.exists(split_dir): os.mkdir(split_dir)\n",
    "    with open(split_dir+'val.json', 'w') as val_file:\n",
    "        json.dump(val_annotations, val_file)\n",
    "    with open(split_dir+'train.json', 'w') as train_file:\n",
    "        json.dump(train_annotations, train_file)\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCO Dataset Slicing for Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sahi.slicing import slice_coco\n",
    "import os\n",
    "\n",
    "data_root = '/content/chula-parasite-dataset/Chula-ParasiteEgg-11/Chula-ParasiteEgg-11/Chula-ParasiteEgg-11/data'\n",
    "n_fold_folder = '/content/output_directory/5-fold/'\n",
    "slice_height = 960\n",
    "slice_width = 1280\n",
    "overlap_height_ratio = 0.3\n",
    "overlap_width_ratio = 0.3\n",
    "min_area_ratio = 0.3\n",
    "ignore_negative_samples = True\n",
    "\n",
    "# Specify the fold you want to process\n",
    "fold_to_process = 'fold-0'\n",
    "\n",
    "fold_dir = os.path.join(n_fold_folder, fold_to_process)\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    coco_dict, coco_path = slice_coco(\n",
    "        coco_annotation_file_path=os.path.join(fold_dir, f'{split}.json'),\n",
    "        image_dir=data_root,\n",
    "        output_coco_annotation_file_name=os.path.join(fold_dir, f'cut_{slice_height}x{slice_width}_{split}'),\n",
    "        output_dir=os.path.join(fold_dir, f'cut_{slice_height}x{slice_width}_{split}'),\n",
    "        slice_height=slice_height,\n",
    "        slice_width=slice_width,\n",
    "        overlap_height_ratio=overlap_height_ratio,\n",
    "        overlap_width_ratio=overlap_width_ratio,\n",
    "        verbose=True,\n",
    "        ignore_negative_samples=ignore_negative_samples,\n",
    "        min_area_ratio=min_area_ratio\n",
    "    )\n",
    "\n",
    "file_slicing_info = os.path.join(fold_dir, f'cut_{slice_height}x{slice_width}.txt')\n",
    "with open(file_slicing_info, 'w') as file:\n",
    "    file.write('data_root=' + data_root + '\\n')\n",
    "    file.write('n_fold_folder=' + n_fold_folder + '\\n')\n",
    "    file.write('slice_height=' + str(slice_height) + '\\n')\n",
    "    file.write('slice_width=' + str(slice_width) + '\\n')\n",
    "    file.write('overlap_height_ratio=' + str(overlap_height_ratio) + '\\n')\n",
    "    file.write('overlap_width_ratio=' + str(overlap_width_ratio) + '\\n')\n",
    "    file.write('min_area_ratio=' + str(min_area_ratio) + '\\n')\n",
    "    file.write('ignore_negative_samples=' + str(ignore_negative_samples) + '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
